{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e2a6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c99d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NLTK Setup (Ensure these are downloaded if needed) ---\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# --- Configuration ---\n",
    "# NOTE: Replace the INPUT_FILE with your exact local path for execution!\n",
    "INPUT_FILE = \"raw_data_essay_set1.xlsx\"\n",
    "OUTPUT_FILE = \"essay_dataset.xlsx\"\n",
    "SCORE_FOR_COMMON_WORDS = 12 # Used to define the common features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33af6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLTK components\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Create a translation table to remove punctuation efficiently (similar to your reference code)\n",
    "translator = str.maketrans('', '', string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f06f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_essay(text):\n",
    "    \"\"\"\n",
    "    Combines all preprocessing steps based on the reference code logic, \n",
    "    including case handling, punctuation removal, stopword removal, \n",
    "    and special token grouping.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return []\n",
    "    \n",
    "    raw_tokens = str(text).split() # 1. Split into tokens first\n",
    "    \n",
    "    # 2. Selective Lowercasing (Keep @-words' original case)\n",
    "    cased_tokens = [word if word.startswith('@') else word.lower() for word in raw_tokens]\n",
    "    \n",
    "    # 3 & 4. Join for Punctuation Removal\n",
    "    joined_string = ' '.join(cased_tokens)\n",
    "    clean_string = joined_string.translate(translator)\n",
    "    \n",
    "    # 5. Split into clean tokens (after punctuation removal)\n",
    "    clean_tokens = clean_string.split()\n",
    "    \n",
    "    processed_tokens = []\n",
    "    \n",
    "    for word in clean_tokens:\n",
    "        \n",
    "        # Determine if the token is a potential category token\n",
    "        # (Uppercase letters followed by optional digits: e.g., CAPS1, LOCATION)\n",
    "        # We check the case of the *current* word, which will be uppercase \n",
    "        # only if it was an @-word in the original text (e.g. @CAPS1 -> CAPS1).\n",
    "        category_match = re.match(r'([A-Z]+)\\d*$', word)\n",
    "        \n",
    "        if category_match:\n",
    "            # If it matches, extract the base category (e.g., CAPS1 -> CAPS)\n",
    "            lemmatized_word = category_match.group(1)\n",
    "        else:\n",
    "            # If it's a regular lowercase word, apply standard lemmatization\n",
    "            lemmatized_word = lemmatizer.lemmatize(word)\n",
    "            \n",
    "        # 6. Stopword Removal (Applied after lemmatization/categorization)\n",
    "        if lemmatized_word and lemmatized_word not in stop_words:\n",
    "            processed_tokens.append(lemmatized_word)\n",
    "            \n",
    "    return processed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d235fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_counts_and_clean(df):\n",
    "    \"\"\"Calculates all count features and preprocesses the essay column.\"\"\"\n",
    "    df_result = df.copy()\n",
    "\n",
    "    # Apply the full preprocessing pipeline (Steps 5-9 equivalent)\n",
    "    df_result['processed_tokens'] = df_result['essay'].apply(preprocess_essay)\n",
    "    \n",
    "    # 1. Word Count (Total words in raw text, similar to your mylist.count logic but for raw tokens)\n",
    "    df_result['word_count'] = df_result['essay'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    # 2. Unique Words (Count of unique processed/lemmatized tokens)\n",
    "    df_result['unique_words'] = df_result['processed_tokens'].apply(lambda tokens: len(set(tokens)))\n",
    "\n",
    "    # 3. Stopword Count (Based on processed tokens used in your vectorization)\n",
    "    # The stopword count in your reference code is based on the final lemmatized list (mylist). \n",
    "    # Here, we calculate it based on the words removed during preprocessing.\n",
    "    def count_stopwords_in_raw(essay):\n",
    "        if pd.isna(essay): return 0\n",
    "        \n",
    "        # 1. Apply selective lowercase and punctuation removal on raw text\n",
    "        cased_tokens = [word if word.startswith('@') else word.lower() for word in str(essay).split()]\n",
    "        joined_string = ' '.join(cased_tokens)\n",
    "        clean_string = joined_string.translate(translator)\n",
    "        clean_tokens = clean_string.split()\n",
    "        \n",
    "        # 2. Count stopwords BEFORE processing/categorization\n",
    "        return sum(1 for word in clean_tokens if word in stop_words)\n",
    "\n",
    "    df_result['stopword'] = df_result['essay'].apply(count_stopwords_in_raw)\n",
    "    \n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad5ccff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df_result):\n",
    "    \"\"\"\n",
    "    Implements Task 10: Finds ALL unique processed words from score 12 essays \n",
    "    (the 'terms' in your code) and creates feature columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Filter essays with the target score (equivalent to d1t, d2t, d3t in your code)\n",
    "    high_score_tokens = df_result[df_result['domain1_score'] == SCORE_FOR_COMMON_WORDS]['processed_tokens']\n",
    "\n",
    "    # 2. Aggregate all tokens (equivalent to finding the union of all word sets)\n",
    "    all_high_score_tokens = [token for sublist in high_score_tokens for token in sublist]\n",
    "\n",
    "    # 3. Find ALL unique words (the 'terms' set in your code)\n",
    "    word_counts = Counter(all_high_score_tokens)\n",
    "    common_words = list(word_counts.keys())\n",
    "    \n",
    "    print(f\"Defining features based on ALL {len(common_words)} unique words from essays with score {SCORE_FOR_COMMON_WORDS}.\")\n",
    "    \n",
    "    # 4. Create new feature columns by counting these words in EVERY essay\n",
    "    for word in common_words:\n",
    "        # This is the equivalent of your vector_d(mylist) function applied to all documents\n",
    "        df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
    "        \n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9df16cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from: raw_data_essay_set1.xlsx\n",
      "Defining features based on ALL 1218 unique words from essays with score 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n",
      "C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_18036\\1792307566.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_result[f'feature_{word}'] = df_result['processed_tokens'].apply(lambda tokens: tokens.count(word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final features to: essay_dataset.xlsx\n",
      "\n",
      " Execution Complete.\n",
      "Final DataFrame saved to 'essay_dataset.xlsx' with 1223 columns.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Main Execution Block ---\n",
    "try:\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "    print(f\"Successfully loaded data from: {INPUT_FILE}\")\n",
    "\n",
    "    # 1. Calculate all counts and clean/tokenize the text\n",
    "    df_with_counts = calculate_counts_and_clean(df)\n",
    "\n",
    "    # 2. Create the common word features (Task 10)\n",
    "    df_final = create_feature_matrix(df_with_counts)\n",
    "    \n",
    "    # 3. Finalize columns and save\n",
    "    final_columns = [\n",
    "        'document_number', \n",
    "        'domain1_score', \n",
    "        'word_count', \n",
    "        'stopword', \n",
    "        'unique_words'\n",
    "    ]\n",
    "    # Add all feature columns\n",
    "    final_columns.extend([col for col in df_final.columns if col.startswith('feature_')])\n",
    "    \n",
    "    # Select only the required columns, dropping the original essay and temporary tokens\n",
    "    df_output = df_final[final_columns].copy() \n",
    "\n",
    "    print(f\"Saving final features to: {OUTPUT_FILE}\")\n",
    "    df_output.to_excel(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(\"\\n Execution Complete.\")\n",
    "    print(f\"Final DataFrame saved to '{OUTPUT_FILE}' with {len(df_output.columns)} columns.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n Error: The input file '{INPUT_FILE}' was not found.\")\n",
    "    print(\"Please make sure the file is in the correct location or upload it.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n An unexpected error occurred: {e}\")\n",
    "    print(f\"Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ab170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
